

- Project 1:  [**BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology**](https://aclanthology.org/2021.blackboxnlp-1.43/) (Gessler and Schneider, 2021) ([Code](https://github.com/lgessler/bert-has-uncommon-sense/tree/master))
  Project supervisor: Aina Gar√≠ Soler (aina.gari-soler@inria.fr)
  
Words often have multiple meanings, and some are used more frequently than others (e.g., the noun _duck_ typically refers to an animal but it is also a cricket term). This paper introduces a simple method to investigate how well the BERT model captures less common word meanings. 

- Project 2 : Hate speech detection 
- Project 3 : Translation 
- Project 4 :   [**When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?**](https://openreview.net/pdf?id=KRLUvxh8uaX) (Yuksekgonul et al., 2023) ([Code](https://github.com/vinid/neg_clip)) Project supervisor: Matthieu Futeral (matthieu.futeral@inria.fr)

Despite the success of large vision and language models (VLMs) in many downstream applications, it is unclear how well they encode the compositional relationships between objects and attributes. This paper introduces a simple training method to overcome the shortcomings of VLMs when it comes to embed this compositional relationship.

- Project 5 : Speech recognition in a low resource language
- Project 6 : Speech language models
- Project 7 : language emergence

